quarkus.banner.enabled=false
quarkus.devservices.enabled = false

camel.assistant.qdrant.collection.name=camel
camel.assistant.qdrant.host=${QDRANT_HOST:localhost}
camel.assistant.qdrant.port=${QDRANT_GRPC_PORT:6334}

# Override this for using with a different AI service
# Adjust here to "openai" or build with mvn -P OpenAI
quarkus.langchain4j.chat-model.provider=ollama

quarkus.langchain4j.ollama.chat-model.model-id = ${CHAT_MODEL:mistral:latest}
quarkus.langchain4j.ollama.embedding-model.model-id = ${EMBEDDING_MODEL:all-minlm-l6-v2}
quarkus.langchain4j.ollama.timeout = ${API_TIMEOUT:100s}
quarkus.langchain4j.ollama.base-url = ${API_ENDPOINT:http://localhost:8000}

# Put this config if you want to use this app with OpenAI
quarkus.langchain4j.openai.api-key = ${OPEN_API_KEY:no_api_key}
quarkus.langchain4j.openai.timeout = ${API_TIMEOUT:100s}
quarkus.langchain4j.openai.chat-model.max-tokens = ${API_MAX_TOKENS:4096}
# If using OpenAI endpoint (ie.: chatgpt, set this to gpt-3.5-turbo or similar)
quarkus.langchain4j.openai.chat-model.model-name=${CHAT_MODEL:mistral:latest}
quarkus.langchain4j.openai.base-url = ${API_ENDPOINT:http://localhost:8000/v1/}
quarkus.langchain4j.openai.*.chat-model.temperature=0.3
quarkus.langchain4j.openai.embedding-model.model-name=${EMBEDDING_MODEL:all-minlm-l6-v2}
