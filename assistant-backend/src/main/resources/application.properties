quarkus.banner.enabled=false

camel.assistant.qdrant.collection.name=camel
camel.assistant.qdrant.host=${QDRANT_HOST:localhost}
camel.assistant.qdrant.port=${QDRANT_GRPC_PORT:6334}

# Override this for using with a different AI service
quarkus.langchain4j.chat-model.provider=ollama

#quarkus.langchain4j.ollama.chat-model.model-id=orca-mini
#quarkus.langchain4j.ollama.embedding-model.model-id=all-minlm-l6-v2
#quarkus.langchain4j.ollama.timeout=100s

# Put this config if you want to use this app with OpenAI
#quarkus.langchain4j.openai.api-key=${OPEN_API_KEY}
#quarkus.langchain4j.openai.*.chat-model.model-name=gpt-3.5-turbo
#quarkus.langchain4j.openai.*.chat-model.temperature=0.3
#quarkus.langchain4j.openai.embedding-model.model-name=all-minlm-l6-v2

# To use an OpenAI-compatible API
%local-openai.quarkus.devservices.enabled = false
%local-openai.quarkus.langchain4j.chat-model.provider = openai
%local-openai.quarkus.langchain4j.openai.api-key = no_api_key
%local-openai.quarkus.langchain4j.openai.base-url = http://localhost:8000/v1/
%local-openai.quarkus.langchain4j.openai.timeout = 100s
%local-openai.quarkus.langchain4j.openai.*.chat-model.max-tokens = 4096